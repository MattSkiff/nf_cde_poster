<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">



<title>cde_nfs.utf8</title>

<script src="index_files/header-attrs-2.6/header-attrs.js"></script>





<!--
Font-awesome icons ie github or twitter
-->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/brands.css" integrity="sha384-n9+6/aSqa9lBidZMRCQHTHKJscPq6NW4pCQBiMmHdUCvPN8ZOg2zJJTkC7WIezWv" crossorigin="anonymous">

<!--
Google fonts api stuff
-->
<link href='https://fonts.googleapis.com/css?family=Helvetica' rel='stylesheet'>
<link href='https://fonts.googleapis.com/css?family=Rasa' rel='stylesheet'>

<!--
Here are the required style attributes for css to make this poster work :)
-->
<style>
@page {
size: 23.4in 36in;
margin: 0;
padding: 0;
}
body {
margin: 0px;
padding: 0px;
width: 23.4in;
height: 36in;
text-align: justify;
font-size: 28.5px;
line-height: 1.05;
}
/* RMarkdown Class Styles */
/* center align leaflet map,
from https://stackoverflow.com/questions/52112119/center-leaflet-in-a-rmarkdown-document */
.html-widget {
margin: auto;
position: sticky;
margin-top: 2cm;
margin-bottom: 2cm;
}
.leaflet.html-widget.html-widget-static-bound.leaflet-container.leaflet-touch.leaflet-fade-anim.leaflet-grab.leaflet-touch-drag.leaflet-touch-zoom {
position: sticky;
width: 100%;
}
pre.sourceCode.r {
background-color: #dddddd40;
border-radius: 4mm;
padding: 4mm;
width: 75%;
margin: auto;
margin-top: 1em;
margin-bottom: 1em;
/* align-items: center; */
}
code.sourceCode.r{
background-color: transparent;
font-size: 20pt;
border-radius: 2mm;
}
code {
font-size: 25pt;
font-family: monospace;
background-color: #9e8a8a24;
color: #1a1818;
padding: 1.2mm;
line-height: 1;
border-radius: 2mm;
}
caption {
margin-bottom: 10px;
font-size: 20pt;
font-style: italic;
}

tbody tr:nth-child(odd) {
    background-color: #9e8a8a20;
}
.table>thead>tr>th, .table>tbody>tr>th, .table>tfoot>tr>th, .table>thead>tr>td, .table>tbody>tr>td, .table>tfoot>tr>td{
  border-spacing: 0;
  font-size: 40%;
  border-style: none;
  padding-top: 15px;
  padding-bottom: 15px;
  padding-right: 1em;
  padding-left: 1em;
  line-height: 1em;
}
table {
  margin: auto;
}
th {
  padding-left: 5mm;
  padding-right: 5mm;
}
.caption {
font-size: 20pt;
font-style: italic;
padding-top: 0;
}
.references {
font-size: 20px;
line-height: 90%;
}
/* Create three unequal columns that floats next to each other */
.column {
float: left;
padding: 0px;
}
.outer {
width: 23.4in;
height: calc(36in *  (1 - 0.10 - 0.10 - 0.01) );
-webkit-column-count: 3; /* Chrome, Safari, Opera */
-moz-column-count: 3; /* Firefox */
column-count: 3;
-webkit-column-fill: auto;
-moz-column-fill: auto;
column-fill: auto;
column-gap: 0;
padding-left: 0cm;
padding-right: 0cm;
/* -webkit-column-rule-width: 50%;
-moz-column-rule-width: 50%;
column-rule-width: 50%; */
-webkit-column-rule-style: none;
-moz-column-rule-style: none;
column-rule-style: none;
-webkit-column-rule-color: black;
-moz-column-rule-color: black;
column-rule-color: black;
background-color: #ffffff;
font-family: Rasa;
margin-top: calc(36in *  0.10 );
padding-top: 1em;
padding-bottom: 1em;
}
span.citation {
  color: #9e8a8a;
  font-weight: bold;
}
a {
text-decoration: none;
color: #9e8a8a;
}
#title {
font-size: 125pt;
text-align: left;
margin: 0;
line-height: 98%;
border-bottom: 0;
font-weight: normal;
background: 0;
}
#author {
color: #1a1818;
margin: 0;
line-height: 85%;
font-size: 1.11em;
}
#affiliation {
padding-top: 0.1em;
color: ;
font-style: italic;
font-size: 25px;
margin: 0;
}
sup {
color: #cc0000;
}
.affiliation sup {
font-size: 20px;
}
.author {
text-align: left;
}
.author sup {
font-size: 30px;
}
.author_extra {
color: #9e8a8a;
margin: 0;
line-height: 85%;
font-size: 35px;
text-align: left;
}
.outer h1, h2, h3, h4, h5, h6 {
text-align: center;
margin: 0;
font-weight: bold;
}
.section h1 {
  text-align:center;
  padding-bottom:5px;
  background:
    linear-gradient(
      to left,
      #ffffff 1%,
      #ffffff 20%,
      #1a181875 33%,
      #1a1818 50%,
      #1a181875 66%,
      #ffffff 80%,
      #ffffff 99%
    )
    left
    bottom
    #ffffff
    no-repeat;
  background-size:100% 5px ;
  margin-top: 0.5em;
  margin-bottom: 0.5em;
}
.outer h2 {
text-align: center;
}
.outer p, .level2 {
color: #000000;
}
.outer ol {
padding-left: 8%;
padding-right: 8%;
text-align: left;
}
.main {
width: 23.4in;
height: calc(36in * 0.10);
position: absolute;
background-color: #1a1818;
color: #ffffff90;
font-family: Helvetica;
background-image: linear-gradient(#1a1818 50%,#9e8a8a);
}
.main strong {
color: #ffffff;
}
.main strong > sup {
color: #ffffff;
}
.main sup {
color: #ffffff90;
}
#main-img-left {
width: 10%;
left: 0.5in;
bottom: 0.2in;
position: absolute;
}
#main-img-center {
width: 10%;
left: calc(23.4in * 0.45);
bottom: 0.5in;
position: absolute;
}
#main-img-right {
width: 10%;
right: 0.5in;
bottom: 0.2in;
position: absolute;
}
.main p {
font-size: 130px;
font-family: Helvetica;
text-align: center;
margin: 0;
position: absolute;
top: 50%;
-ms-transform: translateY(-50%);
transform: translateY(-50%);
margin-left: 1em;
}
.fab {
color: #00000030;
font-size: 25px;
}
.twitter, i {
color: #00000030;
font-size: 35px;
text-decoration: none;
}
a.email {
text-decoration: none;
color: #00000030;
font-size: 35px;
}
.envelope {
color: #00000030;
font-size: 5px;
text-decoration: none;
}
.poster_wrap {
width: 23.4in;
height: 36in;
padding: 0cm;
}
.main_bottom {
width: 23.4in;
height: calc(36in * 0.10);
margin-top: calc(36in * (1 - 0.10));
position: absolute;
background-color: #1a1818;
background-image: linear-gradient(#9e8a8a 10%, #1a1818);
}
.section {
  padding-left: 10mm;
  padding-right: 10mm;
}
span > #tab:mytable {
  font-weight: bold;
}
.orcid img {
  width: 3%;
}
.emphasis {
  background-color: #008080;
  color: #ffffff;
  border: solid #0b2045 3mm;
  margin: 1em;
  padding-left: 0;
  padding-right: 0;
}
.emphasis h1 {
  font-weight: bold;
  background: none;
  background-color: #0b2045;
  padding-bottom: 5mm;
  padding-top: 1mm;
  margin-top: -1mm;
  margin-right: -1mm;
  margin-left: -1mm;
}
.emphasis blockquote {
  border: 0;
}
.emphasis ol {
  padding: 0;
  padding-left: 8%;
  font-size: 100%;
  font-weight: bold;
}
.emphasis p {
  color: #ffffff;
}
</style>
</head>
<body>


<div class="poster_wrap">

<div class="column outer">
<div class="section">

<h3 id="author" class="author">

Matthew Skiffington<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a><sup> </sup><br>
<a class="twitter" href="https://mobile.twitter.com/mattskiff_"><i class="fab fa-twitter"></i>&nbsp;&nbsp;@mattskiff_</a><br>

<a class='envelope'><i class="fas fa-envelope"></i></a> <a href="mailto:mks29@students.waikato.ac.nz" class="email">mks29@students.waikato.ac.nz</a> <br>
</h3>

<h5 id="author_extra", class="author_extra">
</h5>


<p id="affiliation" class="affiliation">
<sup></sup> Department of Computer Science, University of Waikato
</p>
</div>

<!-- logo sizing -->
<style>
.main p {
margin-left: 0em;
}
#main-img-left {
 width: 35.75%;
 height: 72.5%;
 bottom: 0.4in;
}
#code {
 font-size: 30px;
}
#main-img-center {
 width: 36.75%;
 height: 71.5%;
}
#main-img-right {
 bottom: 0.4in;
}
.footnotes {
  font-size: 16pt;
}

</style>
<!-- https://stackoverflow.com/questions/1409649/how-to-change-the-height-of-a-br -->
<hr style="height:5pt; visibility:hidden;" />
<div id="conditional-density-estimation" class="section level2">
<h2>Conditional Density Estimation</h2>
<div class="figure"><span id="fig:qr"></span>
<img src="index_files/figure-html/qr-1.png" alt="\label{fig:qr}QR code for CDE animation" width="30%" style="float:right; padding:10px" />
<p class="caption">
Figure 1: QR code for CDE animation
</p>
</div>
<p>Conditional density estimation (CDE) is a form of supervised learning with methods in statistics, machine learning and deep learning. It is a generalisation of regression. Instead of predicting a point estimate <span class="math inline">\(\hat{y}\)</span> and generating a confidence or credible interval <span class="math inline">\(\hat{y}\pm CI\)</span>, the task is to predict the full conditional density <span class="math inline">\(p(y|x)\)</span> of the data for a given query point <span class="math inline">\(x\)</span>, an improved form of <strong>uncertainty quantification</strong>.</p>
<p>Figure <a href="#fig:cde">2</a> shows Kernel-CDE <span class="citation"><a href="#ref-bashtannyk2001bandwidth" role="doc-biblioref">[1]</a></span> <span class="citation"><a href="#ref-rosenblatt1969conditional" role="doc-biblioref">[2]</a></span> using the faithful geyser data via the <code>hdrcde</code> R package, demonstrating an improvement in uncertainty quantification by using CDE instead of intervals. Early CDE methods included Kernel-CDE, Mixture Density Networks <span class="citation"><a href="#ref-carney2005predicting" role="doc-biblioref">[3]</a></span> and discretisation of the target variable via class probability estimators <span class="citation"><a href="#ref-frank2009conditional" role="doc-biblioref">[4]</a></span> (Figure <a href="#fig:qr">1</a>). Modern methods for CDE include Random Forest-CDE <span class="citation"><a href="#ref-pospisil2018rfcde" role="doc-biblioref">[5]</a></span> and Bottleneck Conditional Density Estimation, a variation on Conditional-VAEs <span class="citation"><a href="#ref-shu2017bottleneck" role="doc-biblioref">[6]</a></span>.</p>
<div class="figure"><span id="fig:cde"></span>
<img src="index_files/figure-html/cde-1.png" alt="\label{fig:cde}Demonstration of estimation using KCDE vs Simple Linear Regression &amp; Prediction Intervals" width="100%" />
<p class="caption">
Figure 2: Demonstration of estimation using KCDE vs Simple Linear Regression &amp; Prediction Intervals
</p>
</div>
</div>
<div id="normalising-flows" class="section level2">
<h2>Normalising Flows</h2>
<p>Normalising flows (NFs) are sequences of invertible, differentiable, composable, transformations (bijections) on a base probability distribution (often a simple Gaussian) to approximate the true density, which may be skewed, multi-modal or complex (even discontinuous) <span class="citation"><a href="#ref-kobyzev2020normalizing" role="doc-biblioref">[7]</a></span>. NFs were proposed as a density estimation procedure <span class="citation"><a href="#ref-tabak2010density" role="doc-biblioref">[8]</a></span>, then for use as approximate posteriors in variational inference <span class="citation"><a href="#ref-rezende2015variational" role="doc-biblioref">[9]</a></span>. They came to prominence for efficiency and expressiveness in both sampling (generative direction) and density evaluation (normalising direction). NFs fit alongside VAEs and GANs as recent deep learning generative models, however, VAEs and GANs are not efficient for density evaluation.</p>
<blockquote>
<p><em>By the term normalising flows people mean bijections which are convenient to compute, invert, and calculate the determinant of their Jacobian</em> <span class="citation"><a href="#ref-kobyzev2020normalizing" role="doc-biblioref">[7]</a></span>.</p>
</blockquote>
<!--

>  <footer>--- Kobyzev et al, "Normalizing Flows: An Introduction and Review of Current Methods" (2020)</footer>

-->
<div class="figure"><span id="fig:nfs"></span>
<img src="index_files/figure-html/nfs-1.png" alt="\label{fig:nfs}Expressiveness and efficiency varies by choice of flow" width="100%" />
<p class="caption">
Figure 3: Expressiveness and efficiency varies by choice of flow
</p>
</div>
<p>Normalising flows are trained by maximising log-likelihood via stochastic gradient descent, or minimising Kullback-Liebler divergence when variational inference is used. Three properties are important for NFs <span class="citation"><a href="#ref-kobyzev2020normalizing" role="doc-biblioref">[7]</a></span>:</p>
<ul>
<li>Efficiency</li>
<li>Expressiveness</li>
<li>Invertibility</li>
</ul>
<p>The number of layers and class of model both influence the expressiveness of the trained distribution. Figure <a href="#fig:nfs">3</a> shows a sample from a Multivariate Normal: <span class="math inline">\(\mathbf{x} \sim \mathcal{N}(\mathcal{u},I)\)</span> transformed using two simple (inexpressive) linear <span class="math inline">\(g(x) = \mathbf{A}\mathbf{x} + b\)</span> flows, where <span class="math inline">\(A_1 := diag(v), A_2 := tri(v), v\sim U(0,3)\)</span> and <span class="math inline">\(b \sim U(-3,3), \mathbf{x} \in \mathcal{R^2}\)</span>. For <span class="math inline">\(A_1\)</span> and <span class="math inline">\(A_2\)</span>, positive entries on the diagonal ensure invertibility. However, moving from a diagonal to triangular matrix incurs a computation cost, moving from <span class="math inline">\(\mathcal{O}(d)\)</span> to <span class="math inline">\(\mathcal{O}(d^2)\)</span> when calculating the inverse.</p>
<p>Practical NF models often use <strong>coupling</strong> functions (NICE, RealNVP, Neural Spline Flows, Glow). Coupling functions split the input into disjoint partions, applying an arbitrarily complex conditioning function (e.g. an invertible neural network) to one. Other models use coupling functions where the conditioner is <strong>autoregressive</strong> (Masked Autoregressive Flows, Inverse Autoregressive Flows, Neural Autoregressive Flows). Recent developments include continuous NFs using neural ordinary differential equations (e.g. FFJORD), work on ordinal data and on manifold learning <span class="citation"><a href="#ref-kobyzev2020normalizing" role="doc-biblioref">[7]</a></span>.</p>
</div>
<div id="nfs-for-cde" class="section level2">
<h2>NFs for CDE</h2>
<p>Normalising flows find applications in conditional class probability estimation, conditional image generation and multivariate time series prediction. Work on CDE with NFs is limited. This includes Bayesian NFs, with a framework for priors over CDE estimators using Bayesian neural networks with variational inference <span class="citation"><a href="#ref-trippe2018conditional" role="doc-biblioref">[10]</a></span>. CDE using Masked Autoregressive Flows and Real NVP by conditioning each term in the chain rule of probability with the inclusion of <span class="math inline">\(y\)</span> at every layer was proposed in 2017 <span class="citation"><a href="#ref-papamakarios2017masked" role="doc-biblioref">[11]</a></span>. This was explored while introducing noise regularisation for CDE in 2019 <span class="citation"><a href="#ref-rothfuss2019noise" role="doc-biblioref">[12]</a></span>. Conditional NFs for structured prediction have also been developed <span class="citation"><a href="#ref-winkler2019learning" role="doc-biblioref">[13]</a></span>. Progress in using NFs for CDE has been limited by the following factors:</p>
<ul>
<li>Computational difficulty of scaling NFs to large data sets - newer continuous NF models are restricted to usage on small image benchmark sets <span class="citation"><a href="#ref-grathwohl2018ffjord" role="doc-biblioref">[14]</a></span>.</li>
<li>Deep learning focus is often in areas of traditional strength, e.g. image data.</li>
</ul>
<p>Figure <a href="#fig:nfcdeex">4</a> demonstrates using NFs to create CDEs of rainfall &amp; soil moisture (data source: NIWA, 10 months). We scale the data, train the flow, and condition on two levels of rainfall <span class="math inline">\([-1,1]\)</span>, showing the conditional densities. Note the separate estimates have different modalities, which could reflect a differing seasonal effect. Other climatological and spatio-temporal factors would be extra sources of variation not considered. The marginals are simulated well while the joint is poorly approximated (and noisy).</p>
<hr style="height:10pt; visibility:hidden;" />
<div class="figure"><span id="fig:nfcdeex"></span>
<img src="figures/combined.png" alt="\label{fig:nfcdeex}Traing NFs for CDE with climatological data" width="100%" style="float:right; padding:10px" />
<p class="caption">
Figure 4: Traing NFs for CDE with climatological data
</p>
</div>
<p>The probabilistic programming libraries <code>pyro</code> (for <code>PyTorch</code>) and <code>tensorflow probability</code> both implement NFs.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<!-- rmarkdown::render(input = "cde_nfs.Rmd",output_file = "index.html") -->
<div id="refs" class="references csl-bib-body">
<div id="ref-bashtannyk2001bandwidth" class="csl-entry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">D. M. Bashtannyk and R. J. Hyndman, <span>“Bandwidth selection for kernel conditional density estimation,”</span> <em>Computational Statistics &amp; Data Analysis</em>, vol. 36, no. 3, pp. 279–298, 2001.</div>
</div>
<div id="ref-rosenblatt1969conditional" class="csl-entry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">M. Rosenblatt, <span>“Conditional probability density and regression estimators,”</span> <em>Multivariate analysis II</em>, vol. 25, p. 31, 1969.</div>
</div>
<div id="ref-carney2005predicting" class="csl-entry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">M. Carney, P. Cunningham, J. Dowling, and C. Lee, <span>“Predicting probability distributions for surf height using an ensemble of mixture density networks,”</span> in <em>Proceedings of the 22nd international conference on machine learning</em>, 2005, pp. 113–120.</div>
</div>
<div id="ref-frank2009conditional" class="csl-entry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">E. Frank and R. R. Bouckaert, <span>“Conditional density estimation with class probability estimators,”</span> in <em>Asian conference on machine learning</em>, 2009, pp. 65–81.</div>
</div>
<div id="ref-pospisil2018rfcde" class="csl-entry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">T. Pospisil and A. B. Lee, <span>“Rfcde: Random forests for conditional density estimation,”</span> <em>arXiv preprint arXiv:1804.05753</em>, 2018.</div>
</div>
<div id="ref-shu2017bottleneck" class="csl-entry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">R. Shu, H. H. Bui, and M. Ghavamzadeh, <span>“Bottleneck conditional density estimation,”</span> in <em>International conference on machine learning</em>, 2017, pp. 3164–3172.</div>
</div>
<div id="ref-kobyzev2020normalizing" class="csl-entry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">I. Kobyzev, S. Prince, and M. Brubaker, <span>“Normalizing flows: An introduction and review of current methods,”</span> <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2020.</div>
</div>
<div id="ref-tabak2010density" class="csl-entry">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">E. G. Tabak, E. Vanden-Eijnden, and others, <span>“Density estimation by dual ascent of the log-likelihood,”</span> <em>Communications in Mathematical Sciences</em>, vol. 8, no. 1, pp. 217–233, 2010.</div>
</div>
<div id="ref-rezende2015variational" class="csl-entry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">D. Rezende and S. Mohamed, <span>“Variational inference with normalizing flows,”</span> in <em>International conference on machine learning</em>, 2015, pp. 1530–1538.</div>
</div>
<div id="ref-trippe2018conditional" class="csl-entry">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">B. L. Trippe and R. E. Turner, <span>“Conditional density estimation with bayesian normalising flows,”</span> <em>arXiv preprint arXiv:1802.04908</em>, 2018.</div>
</div>
<div id="ref-papamakarios2017masked" class="csl-entry">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">G. Papamakarios, T. Pavlakou, and I. Murray, <span>“Masked autoregressive flow for density estimation,”</span> <em>arXiv preprint arXiv:1705.07057</em>, 2017.</div>
</div>
<div id="ref-rothfuss2019noise" class="csl-entry">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">J. Rothfuss <em>et al.</em>, <span>“Noise regularization for conditional density estimation,”</span> <em>arXiv preprint arXiv:1907.08982</em>, 2019.</div>
</div>
<div id="ref-winkler2019learning" class="csl-entry">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">C. Winkler, D. Worrall, E. Hoogeboom, and M. Welling, <span>“Learning likelihoods with conditional normalizing flows,”</span> <em>arXiv preprint arXiv:1912.00042</em>, 2019.</div>
</div>
<div id="ref-grathwohl2018ffjord" class="csl-entry">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">W. Grathwohl, R. T. Chen, J. Bettencourt, I. Sutskever, and D. Duvenaud, <span>“Ffjord: Free-form continuous dynamics for scalable reversible generative models,”</span> <em>arXiv preprint arXiv:1810.01367</em>, 2018.</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Poster produced via the <em>posterdown</em> package. The code to reproduce this poster is at <strong><a href="https://github.com/MattSkiff/nf_cde_poster" class="uri">https://github.com/MattSkiff/nf_cde_poster</a></strong>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

</div>
<div class="main">
<p><strong>Normalising Flows</strong> for <strong>Conditional Density Estimation</strong></p>
</div>
<div class="main_bottom">
<img id="main-img-left" src=figures/TAIAO_logo_1000x320_upscaled.png>
<img id="main-img-center" src=figures/SVGFullColourHorizontalRGBforredbackground_upscaled.png>
<img id="main-img-right" src=https://raw.githubusercontent.com/brentthorne/posterdown/master/images/betterhexlogo.png>
</div>
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
var script = document.createElement("script");
script.type = "text/javascript";
var src = "true";
if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
if (location.protocol !== "file:" && /^https?:/.test(src))
src = src.replace(/^https?:/, '');
script.src = src;
document.getElementsByTagName("head")[0].appendChild(script);
})();
</script>


</body>
</html>
